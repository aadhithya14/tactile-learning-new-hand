defaults:
    - encoder: resnet18 # alexnet
    - learner: tactile_byol
    - dataset: vision_dataset # tactile_tdex_dataset
    - optimizer: adam

seed: 42
device: cuda

learner_type: image_byol # Can be image_byol, tactile_stacked_byol # tactile_stacked_byol tactile_linear_byol, bc, tactile_byol
self_supervised: true

# Hyperparameters to be used everywhere
batch_size: 32
tactile_image_size: 224 # This could be changed for stacked or shared architectures
vision_image_size: 480
hidden_dim: 64
train_epochs: 1000
save_frequency: 10
train_dset_split: 0.95

distributed: true
num_workers: 4
world_size: 1
num_gpus: 4

# Data path to be set
object: cup_picking
experiment: ${learner_type}_bs_${batch_size}_${object}_after_rss # Name of the experiment that the models are saved
data_dir: /home/irmak/Workspace/Holo-Bot/extracted_data/${object}/after_rss
checkpoint_dir: ??? # Will be set to hydra dir inside the code

# logger
logger: true # To init logger or not
log_frequency: 1

# hydra configuration - should be received separately
hydra:
    run:
        dir: /home/irmak/Workspace/tactile-learning/tactile_learning/out/${now:%Y.%m.%d}/${now:%H-%M}_${experiment}
