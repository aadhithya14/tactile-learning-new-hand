defaults:
    # - _self_
    # - agent: cpn # forward model will also be added in the future - TODO: maybe add a wrapper agent class?
    # - encoder: resnet18
    # - trans: mlp
    # - optimizer: adam
    # - agent: pli
    # - optimizer: adam
    # - agent: sbfd
    # - optimizer: adam
    # - trans: mlp
    # - agent: bc
    # - optimizer: adam
    - agent: diffusion
    - optimizer: adam

seed: 42
device: cuda

agent_type: bc
train_epochs: 1000
save_frequency: 10 # Frequency to save the model - there will be a test in each step
train_dset_split: 0.8
diff_n_steps: 200

# Hyperparameters to be used everywhere
batch_size: 64
lr: 1e-3
weight_decay: 1e-5
# hidden_dim: 64 # Expand to 64 first then to z_dim
# action_dim:  
distributed: true
num_workers: 4
world_size: 1
num_gpus: 4

fps: 15 # This should be the same as the all the fps in saving - little differences are not going to be taken
video_type: rgb # NOTE: you could remove this if you want to use both

# this needs to be specified manually
# experiment: ${agent_type}_ref_${pos_ref}_lf_${agent.loss_fn}_fi_${frame_interval}_pt_${pos_type}_bs_${batch_size}_hd_${hidden_dim}_lr_${lr}_zd_${z_dim}
experiment: ${agent_type}_ref_${pos_ref}_fi_${frame_interval}_pt_${pos_type}_bs_${batch_size}_hd_${hidden_dim}_lr_${lr}_zd_${z_dim}

# data_dir: /home/irmak/Workspace/DAWGE/src/dawge_planner/data/box_orientation_1_demos/train_demos
data_dir: /home/irmak/Workspace/Holo-Bot/extracted_data
checkpoint_dir: ??? # Will be set to hydra dir inside the code

# logger
log_frequency: 1

# hydra configuration - should be received separately
hydra:
    run:
        dir: /home/irmak/Workspace/tactile-learning/tactile_learning/out/${now:%Y.%m.%d}/${now:%H-%M}_${experiment}