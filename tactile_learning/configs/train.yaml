defaults:
    - encoder: resnet18
    - dataset: tactile_vision_dataset
    - optimizer: adam

seed: 42
device: cuda

learner_type: image_byol # bc, tactile_byol
self_supervised: true
preprocess: false
train_epochs: 1000
save_frequency: 10 # Frequency to save the model - there will be a test in each step
train_dset_split: 0.9 # When self_supervised all data is used for encoder training

# Hyperparameters to be used everywhere
batch_size: 32 # 1028
tactile_image_size: 16
vision_image_size: 480
tactile_info_dim: 720 # 15*16*3
joint_pos_dim: 16
hidden_dim: 64
distributed: true
num_workers: 4
world_size: 1
num_gpus: 4

fps: 15 # This should be the same as the all the fps in saving - little differences are not going to be taken
video_type: rgb # NOTE: you could remove this if you want to use both

# this needs to be specified manually
object: box_handle_lifting/box_location_changing/training
experiment: ${learner_type}_bs_${batch_size}_${object}
data_dir: /home/irmak/Workspace/Holo-Bot/extracted_data/${object}
checkpoint_dir: ??? # Will be set to hydra dir inside the code

# logger
logger: true # To init logger or not
log_frequency: 1

# hydra configuration - should be received separately
hydra:
    run:
        dir: /home/irmak/Workspace/tactile-learning/tactile_learning/out/${now:%Y.%m.%d}/${now:%H-%M}_${experiment}
