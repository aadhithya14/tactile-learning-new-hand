{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to visualize demonstrations according to the timestamps\n",
    "# First get the first timestamp of the xela sensor\n",
    "# Then with given fps given get image frames - find closest tactile and image observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tactile_learning.datasets.preprocess import dump_video_to_images, get_closest_id\n",
    "from tactile_learning.utils.visualization import plot_tactile_sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decimal\n",
    "\n",
    "# Get the metadata of images and tactile information\n",
    "def get_desired_indices(root, fps): # frames per second from the video to receive\n",
    "    image_metadata_path = os.path.join(root, 'cam_0_rgb_video.metadata')\n",
    "    tactile_info_path = os.path.join(root, 'touch_sensor_values.h5')\n",
    "\n",
    "    with open(image_metadata_path, 'rb') as f:\n",
    "        image_metadata = pickle.load(f)\n",
    "        image_timestamps_array = np.asarray(image_metadata['timestamps'])\n",
    "        # print('image_timestamps: {}'.format(np.asarray(image_metadata['timestamps'])[0]))\n",
    "        # print('image_timestamps: {}'.format(np.asarray(image_metadata['timestamps'])[-1]))\n",
    "        image_timestamps = np.asarray(image_metadata['timestamps']) / 1000.\n",
    "    with h5py.File(tactile_info_path, 'r') as f:\n",
    "        tactile_timestamps = f['timestamps'][()]\n",
    "        # print('tactile_timestamps: {}'.format(tactile_timestamps[0]))\n",
    "        # print('tactile_timestamps: {}'.format(tactile_timestamps[-1]))\n",
    "\n",
    "    # Compare the timestamps and calculate how much we should divide the image_timestamps - it can differ\n",
    "    # img_ts = decimal.Decimal(str(image_timestamps_array[0]))\n",
    "    # img_decimal_num = len(str(image_timestamps_array[0]).split(\".\")[0])\n",
    "    # print(img_decimal_num)\n",
    "    # tactile_ts = decimal.Decimal(str(tactile_timestamps[0]))\n",
    "    # tactile_decimal_num = tactile_ts.as_tuple()\n",
    "    # tactile_decimal_num = len(str(tactile_timestamps[0]).split(\".\")[0])\n",
    "    # print(tactile_decimal_num)\n",
    "    # print('img_decimal_num: {}, tactile_decimal_num: {}, diff: {}'.format(\n",
    "    #     img_decimal_num, tactile_decimal_num, img_decimal_num - tactile_decimal_num\n",
    "    # ))\n",
    "    # img_divider = 10**(abs(img_decimal_num - tactile_decimal_num))\n",
    "    # img_divider = 100\n",
    "    # print(img_divider)\n",
    "    # image_timestamps = image_timestamps_array / img_divider\n",
    "    # print(image_timestamps_array[0] / img_divider)\n",
    "\n",
    "    image_id, tactile_id = 0, 0\n",
    "    curr_timestamp = tactile_timestamps[0] # These timestamps are in seconds\n",
    "    image_id = get_closest_id(image_id, curr_timestamp, image_timestamps)\n",
    "\n",
    "    tactile_indices, image_indices = [], []\n",
    "    tactile_indices.append(tactile_id)\n",
    "    image_indices.append(image_id)\n",
    "\n",
    "    frame_period = 1. / fps\n",
    "    while(True):\n",
    "        curr_timestamp += frame_period\n",
    "        tactile_id = get_closest_id(tactile_id, curr_timestamp, tactile_timestamps)\n",
    "        image_id = get_closest_id(image_id, curr_timestamp, image_timestamps)\n",
    "        # print('tactile_timestamps[{}]: {}, image_timestamps[{}]: {}'.format(\n",
    "        #     tactile_id, tactile_timestamps[tactile_id], image_id, image_timestamps[image_id]\n",
    "        # ))\n",
    "\n",
    "        if curr_timestamp > tactile_timestamps[tactile_id] and curr_timestamp > image_timestamps[image_id]:\n",
    "            break\n",
    "\n",
    "        tactile_indices.append(tactile_id)\n",
    "        image_indices.append(image_id)\n",
    "\n",
    "    assert len(tactile_indices) == len(image_indices)\n",
    "    return tactile_indices, image_indices\n",
    "\n",
    "    # print('tactile_indices: {}, image_indices: {}'.format(tactile_indices, image_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dump_states(root, tactile_indices, image_indices):\n",
    "    # Make directory to dump the visualization\n",
    "    pbar = tqdm(total=len(tactile_indices))\n",
    "\n",
    "    with h5py.File(os.path.join(root, 'touch_sensor_values.h5'), 'r') as f:\n",
    "        all_tactile_values = f['sensor_values'][()]\n",
    "\n",
    "    viz_dir = os.path.join(root, 'visualization')\n",
    "    os.makedirs(viz_dir, exist_ok=True)\n",
    "    \n",
    "    video_path = os.path.join(root, f'cam_0_rgb_video.avi')\n",
    "    vidcap = cv2.VideoCapture(video_path)\n",
    "    success, image = vidcap.read()\n",
    "    frame_count = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_id = 0\n",
    "    for i in range(len(tactile_indices)):\n",
    "        tactile_id, image_id = tactile_indices[i], image_indices[i]\n",
    "        # print('image_id:')\n",
    "        while frame_id != image_id and success:\n",
    "            # Find the frame that is equal to image_id\n",
    "            success, image = vidcap.read()\n",
    "            frame_id += 1\n",
    "        dump_demo_state(\n",
    "            frame_id = i,\n",
    "            viz_dir = viz_dir,\n",
    "            tactile_values = all_tactile_values[tactile_id,:,:,:],\n",
    "            camera_img = image\n",
    "        )\n",
    "\n",
    "        pbar.update(1)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "        # break\n",
    "        # if i > 10:\n",
    "        #     break\n",
    "\n",
    "\n",
    "def dump_demo_state(frame_id, viz_dir, tactile_values, camera_img):\n",
    "    # tactile_values: (15,16,3)\n",
    "    # print('tactile_values.shape: {}'.format(tactile_values.shape))\n",
    "\n",
    "    fig, axs = plt.subplots(figsize=(20,20), nrows=4, ncols=4)\n",
    "    for row_id in range(4):\n",
    "        for column_id in range(4):\n",
    "            if row_id + column_id > 0: # The top left axis should stay empty\n",
    "                plot_tactile_sensor(\n",
    "                    ax = axs[column_id][row_id],\n",
    "                    sensor_values = tactile_values[row_id*4 + column_id-1],\n",
    "                    title = f'Sensor {row_id*4+column_id-1}'\n",
    "                )\n",
    "    fig.suptitle('Tactile State')\n",
    "    fig.savefig(os.path.join(viz_dir, 'Tactile State.png'))\n",
    "    # cv2.imwrite(os.path.join(viz_dir, 'Camera Image.png', image))\n",
    "    fig.clf()\n",
    "    plt.close()\n",
    "\n",
    "    tactile_img = cv2.imread(os.path.join(viz_dir, 'Tactile State.png'))\n",
    "    height_scale = camera_img.shape[0] / tactile_img.shape[0]\n",
    "    tactile_img = cv2.resize(\n",
    "        tactile_img,\n",
    "        (int(tactile_img.shape[1] * height_scale),\n",
    "         int(tactile_img.shape[0] * height_scale))\n",
    "    )\n",
    "    total_img = cv2.hconcat([camera_img, tactile_img])\n",
    "\n",
    "    img_name = 'state_{}.png'.format(str(frame_id).zfill(3))\n",
    "    cv2.imwrite(os.path.join(viz_dir, img_name), total_img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tactile_indices: [0, 22, 43, 61, 80, 100, 120, 140, 161, 179, 199, 219, 239, 258, 278, 297, 317, 337, 357, 376, 396, 416, 436, 455, 474, 494, 514, 534, 553, 573, 593, 612, 632, 652, 672, 691, 709, 729, 749, 769, 788, 807, 827, 847, 866, 886, 906, 926, 945, 964, 983, 1004, 1024, 1042, 1062, 1083, 1103, 1123, 1141, 1161, 1181, 1201, 1220, 1240, 1260, 1280, 1299, 1318, 1338, 1358, 1377, 1397, 1417, 1437, 1457, 1477, 1496, 1516, 1535, 1555, 1578, 1594, 1614, 1634, 1654, 1672, 1692, 1712, 1732, 1751, 1771, 1791, 1811, 1829, 1848, 1868, 1889, 1908, 1926, 1947, 1966, 1986, 2004, 2025, 2045, 2065, 2085, 2103, 2123, 2144, 2164, 2182, 2202, 2222, 2243, 2261, 2282, 2300, 2320, 2340, 2359, 2378, 2398, 2418, 2438, 2457, 2477, 2496, 2516, 2536, 2555, 2575, 2594, 2614, 2636, 2654, 2673, 2693, 2713, 2733, 2752, 2771, 2792, 2812, 2832, 2850, 2870, 2890, 2910, 2929, 2948, 2969, 2989, 3008, 3028, 3047, 3067, 3086, 3106, 3126, 3146, 3166, 3186, 3206, 3224, 3244, 3264, 3284, 3304, 3323, 3342, 3362, 3382, 3403], image_indices: [70, 76, 82, 88, 94, 100, 106, 112, 118, 124, 130, 136, 142, 148, 154, 160, 166, 172, 178, 184, 190, 196, 202, 208, 214, 220, 225, 231, 237, 243, 249, 255, 261, 267, 273, 279, 285, 291, 297, 303, 308, 314, 320, 326, 332, 338, 344, 350, 355, 361, 367, 373, 379, 385, 391, 397, 403, 408, 414, 420, 426, 432, 438, 444, 450, 456, 462, 468, 474, 480, 486, 492, 498, 504, 510, 516, 521, 527, 533, 539, 545, 551, 557, 563, 569, 575, 581, 587, 593, 599, 605, 611, 617, 623, 629, 635, 641, 647, 653, 659, 665, 671, 677, 683, 689, 695, 701, 707, 713, 719, 725, 730, 736, 742, 748, 754, 760, 766, 772, 778, 784, 790, 796, 802, 808, 814, 820, 826, 832, 838, 844, 850, 856, 862, 868, 874, 880, 886, 892, 898, 904, 910, 916, 922, 928, 934, 940, 946, 952, 958, 964, 970, 976, 982, 988, 994, 1000, 1006, 1012, 1018, 1024, 1030, 1036, 1042, 1048, 1054, 1060, 1066, 1072, 1078, 1084, 1090, 1096, 1102]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [03:14<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "# root = '/home/irmak/Workspace/Holo-Bot/extracted_data/both_robots/demonstration_new_box_opening_1'\n",
    "# roots = [\n",
    "#     '/home/irmak/Workspace/Holo-Bot/extracted_data/both_robots/demonstration_new_box_opening_1',\n",
    "#     '/home/irmak/Workspace/Holo-Bot/extracted_data/both_robots/demonstration_hammer_1',\n",
    "#     '/home/irmak/Workspace/Holo-Bot/extracted_data/both_robots/demonstration_new_book_1',\n",
    "#     '/home/irmak/Workspace/Holo-Bot/extracted_data/both_robots/demonstration_bottle_opening_1',\n",
    "#     '/home/irmak/Workspace/Holo-Bot/extracted_data/both_robots/demonstration_new_reverse_peg_4',\n",
    "#     '/home/irmak/Workspace/Holo-Bot/extracted_data/both_robots/demonstration_new_joystick_2'\n",
    "# ]\n",
    "roots = [\n",
    "    # '/home/irmak/Workspace/Holo-Bot/extracted_data/both_robots/demonstration_handle_grabbing_1',\n",
    "    # '/home/irmak/Workspace/Holo-Bot/extracted_data/both_robots/demonstration_bowl_handle_lifting_4',\n",
    "    # '/home/irmak/Workspace/Holo-Bot/extracted_data/both_robots/demonstration_bowl_handle_lifting_6',\n",
    "    '/home/irmak/Workspace/Holo-Bot/extracted_data/box_handle_lifting/demonstration_11'\n",
    "]\n",
    "\n",
    "retrieval_fps = 5\n",
    "for root in roots:\n",
    "    # print('root: {}'.format(root))\n",
    "    tactile_indices, image_indices = get_desired_indices(root=root, fps=retrieval_fps)\n",
    "    print('tactile_indices: {}, image_indices: {}'.format(tactile_indices, image_indices))\n",
    "    dump_states(root, tactile_indices, image_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 10.4.0 (conda-forge gcc 10.4.0-18)\n",
      "  configuration: --prefix=/home/irmak/miniconda3/envs/tactile_learning --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-vaapi --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/pkg-config\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "[image2 @ 0x556d3ab51640] Pattern type 'glob_sequence' is deprecated: use pattern_type 'glob' instead\n",
      "Input #0, image2, from '/home/irmak/Workspace/Holo-Bot/extracted_data/box_handle_lifting/demonstration_11/visualization/%*.png':\n",
      "  Duration: 00:00:07.00, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: png, rgba(pc), 2000x2000 [SAR 3937:3937 DAR 1:1], 25 fps, 25 tbr, 25 tbn\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (png (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dumping video in root: /home/irmak/Workspace/Holo-Bot/extracted_data/box_handle_lifting/demonstration_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[libx264 @ 0x556d3ab5d440] using SAR=1/1\n",
      "[libx264 @ 0x556d3ab5d440] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "[libx264 @ 0x556d3ab5d440] profile High 4:4:4 Predictive, level 4.0, 4:4:4, 8-bit\n",
      "[libx264 @ 0x556d3ab5d440] 264 - core 164 r3095 baee400 - H.264/MPEG-4 AVC codec - Copyleft 2003-2022 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=4 threads=22 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=10 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to '/home/irmak/Workspace/Holo-Bot/extracted_data/box_handle_lifting/demonstration_11/visualization.mp4':\n",
      "  Metadata:\n",
      "    encoder         : Lavf59.27.100\n",
      "  Stream #0:0: Video: h264 (avc1 / 0x31637661), yuv444p(tv, progressive), 2000x720 [SAR 1:1 DAR 25:9], q=2-31, 10 fps, 10240 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc59.37.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "frame=  175 fps= 90 q=-1.0 Lsize=    5782kB time=00:00:17.20 bitrate=2754.1kbits/s speed=8.84x    \n",
      "video:5779kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.051451%\n",
      "[libx264 @ 0x556d3ab5d440] frame I:1     Avg QP:22.48  size: 53923\n",
      "[libx264 @ 0x556d3ab5d440] frame P:44    Avg QP:20.55  size: 63365\n",
      "[libx264 @ 0x556d3ab5d440] frame B:130   Avg QP:23.70  size: 23658\n",
      "[libx264 @ 0x556d3ab5d440] consecutive B-frames:  0.6%  1.1%  0.0% 98.3%\n",
      "[libx264 @ 0x556d3ab5d440] mb I  I16..4: 28.4% 42.3% 29.3%\n",
      "[libx264 @ 0x556d3ab5d440] mb P  I16..4:  1.0% 19.0%  0.8%  P16..4: 21.2% 15.8% 10.7%  0.0%  0.0%    skip:31.6%\n",
      "[libx264 @ 0x556d3ab5d440] mb B  I16..4:  0.3%  8.5%  0.1%  B16..8: 24.8%  6.9%  2.2%  direct: 4.7%  skip:52.5%  L0:46.4% L1:40.3% BI:13.3%\n",
      "[libx264 @ 0x556d3ab5d440] 8x8 transform intra:91.1% inter:83.3%\n",
      "[libx264 @ 0x556d3ab5d440] coded y,u,v intra: 79.6% 43.9% 40.1% inter: 23.4% 11.8% 11.7%\n",
      "[libx264 @ 0x556d3ab5d440] i16 v,h,dc,p: 45% 27% 20%  9%\n",
      "[libx264 @ 0x556d3ab5d440] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 13% 15% 56%  2%  2%  3%  2%  3%  4%\n",
      "[libx264 @ 0x556d3ab5d440] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 30% 27% 15%  3%  5%  6%  5%  4%  5%\n",
      "[libx264 @ 0x556d3ab5d440] Weighted P-Frames: Y:0.0% UV:0.0%\n",
      "[libx264 @ 0x556d3ab5d440] ref P L0: 32.5%  8.8% 38.6% 20.1%\n",
      "[libx264 @ 0x556d3ab5d440] ref B L0: 68.3% 24.9%  6.8%\n",
      "[libx264 @ 0x556d3ab5d440] ref B L1: 90.3%  9.7%\n",
      "[libx264 @ 0x556d3ab5d440] kb/s:2705.15\n"
     ]
    }
   ],
   "source": [
    "# Turn the images to a video and delete the directory\n",
    "video_fps = 10\n",
    "for root in roots:\n",
    "    print('dumping video in root: {}'.format(root))\n",
    "    video_path = os.path.join(root, 'visualization.mp4')\n",
    "    if os.path.exists(video_path):\n",
    "        os.remove(video_path)\n",
    "    viz_dir = os.path.join(root, 'visualization')\n",
    "    os.system('ffmpeg -r {} -i {}/%*.png -vf scale=2000x720,setsar=1:1 {}'.format(\n",
    "        video_fps, # fps\n",
    "        viz_dir,\n",
    "        video_path\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the img directory\n",
    "\n",
    "for root in roots:\n",
    "    viz_dir = os.path.join(root, 'visualization')\n",
    "    shutil.rmtree(viz_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('tactile_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36852de55b288c46ba617fd48cf310240e4201e2f57004cbdac030fa23152bd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
